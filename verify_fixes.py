#!/usr/bin/env python3
"""
éªŒè¯LandPPT URLå‰ç¼€ä¿®å¤ç»“æœ
æ£€æŸ¥æ˜¯å¦è¿˜æœ‰é‡å¤å‰ç¼€é—®é¢˜
"""

import os
import re
from pathlib import Path
from typing import List, Dict

class URLPrefixVerifier:
    def __init__(self, base_path: str = "/landppt"):
        self.base_path = base_path
        self.issues_found = []
        
    def scan_files(self, directory: str, extensions: List[str]) -> List[str]:
        """æ‰«ææŒ‡å®šç›®å½•ä¸­çš„æ–‡ä»¶"""
        files = []
        for ext in extensions:
            files.extend(Path(directory).rglob(f"*{ext}"))
        return [str(f) for f in files]
    
    def check_for_duplicate_prefixes(self, content: str, file_path: str) -> List[Dict]:
        """æ£€æŸ¥é‡å¤çš„å‰ç¼€é—®é¢˜"""
        issues = []
        lines = content.split('\n')
        
        duplicate_pattern = f"{self.base_path}/{self.base_path}"
        
        for i, line in enumerate(lines, 1):
            if duplicate_pattern in line:
                issues.append({
                    'file': file_path,
                    'line': i,
                    'content': line.strip(),
                    'issue': f'å‘ç°é‡å¤çš„å‰ç¼€: {duplicate_pattern}',
                    'type': 'duplicate_prefix'
                })
        
        return issues
    
    def check_redirect_urls(self, content: str, file_path: str) -> List[Dict]:
        """æ£€æŸ¥é‡å®šå‘URLæ˜¯å¦æ­£ç¡®"""
        issues = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥é‡å®šå‘URL
            if 'RedirectResponse(url=' in line or 'redirect(' in line:
                # åº”è¯¥åŒ…å«åŸºç¡€è·¯å¾„
                if self.base_path not in line:
                    issues.append({
                        'file': file_path,
                        'line': i,
                        'content': line.strip(),
                        'issue': 'é‡å®šå‘URLç¼ºå°‘/landpptå‰ç¼€',
                        'type': 'redirect_missing_prefix'
                    })
                # æ£€æŸ¥é‡å¤å‰ç¼€
                elif f'"{self.base_path}/{self.base_path}' in line or f"'{self.base_path}/{self.base_path}" in line:
                    issues.append({
                        'file': file_path,
                        'line': i,
                        'content': line.strip(),
                        'issue': 'é‡å®šå‘URLæœ‰é‡å¤çš„å‰ç¼€',
                        'type': 'redirect_duplicate_prefix'
                    })
        
        return issues
    
    def check_static_resources(self, content: str, file_path: str) -> List[Dict]:
        """æ£€æŸ¥é™æ€èµ„æºé“¾æ¥"""
        issues = []
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # æ£€æŸ¥é™æ€èµ„æºé“¾æ¥
            if ('src=' in line or 'href=' in line) and '/static/' in line:
                # åº”è¯¥åŒ…å«åŸºç¡€è·¯å¾„
                if f'{self.base_path}/static/' not in line:
                    # æ’é™¤ä¸€äº›ç‰¹æ®Šæƒ…å†µ
                    if not any(skip in line for skip in ['${', 'javascript:', 'http://', 'https://']):
                        issues.append({
                            'file': file_path,
                            'line': i,
                            'content': line.strip(),
                            'issue': 'é™æ€èµ„æºé“¾æ¥ç¼ºå°‘/landpptå‰ç¼€',
                            'type': 'static_resource_missing_prefix'
                        })
        
        return issues
    
    def verify_file(self, file_path: str) -> List[Dict]:
        """éªŒè¯å•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            issues = []
            
            # æ£€æŸ¥é‡å¤å‰ç¼€
            issues.extend(self.check_for_duplicate_prefixes(content, file_path))
            
            # å¦‚æœæ˜¯Pythonæ–‡ä»¶ï¼Œæ£€æŸ¥é‡å®šå‘URL
            if file_path.endswith('.py'):
                issues.extend(self.check_redirect_urls(content, file_path))
            
            # å¦‚æœæ˜¯HTMLæ–‡ä»¶ï¼Œæ£€æŸ¥é™æ€èµ„æº
            if file_path.endswith('.html'):
                issues.extend(self.check_static_resources(content, file_path))
            
            return issues
            
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return []
    
    def run_verification(self, project_root: str = ".") -> Dict:
        """è¿è¡ŒéªŒè¯"""
        print(f"å¼€å§‹éªŒè¯é¡¹ç›®: {project_root}")
        print(f"åŸºç¡€è·¯å¾„: {self.base_path}")
        
        # æ‰«æå…³é”®æ–‡ä»¶
        python_files = self.scan_files(f"{project_root}/src", ['.py'])
        html_files = self.scan_files(f"{project_root}/src", ['.html'])
        js_files = self.scan_files(f"{project_root}/src", ['.js'])
        
        all_issues = []
        
        # éªŒè¯Pythonæ–‡ä»¶
        print(f"\néªŒè¯Pythonæ–‡ä»¶ ({len(python_files)}ä¸ªæ–‡ä»¶)...")
        for file_path in python_files:
            issues = self.verify_file(file_path)
            all_issues.extend(issues)
            if issues:
                print(f"  âŒ {file_path}: å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            else:
                print(f"  âœ… {file_path}: æ— é—®é¢˜")
        
        # éªŒè¯HTMLæ–‡ä»¶
        print(f"\néªŒè¯HTMLæ–‡ä»¶ ({len(html_files)}ä¸ªæ–‡ä»¶)...")
        for file_path in html_files:
            issues = self.verify_file(file_path)
            all_issues.extend(issues)
            if issues:
                print(f"  âŒ {file_path}: å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            else:
                print(f"  âœ… {file_path}: æ— é—®é¢˜")
        
        # éªŒè¯JavaScriptæ–‡ä»¶
        print(f"\néªŒè¯JavaScriptæ–‡ä»¶ ({len(js_files)}ä¸ªæ–‡ä»¶)...")
        for file_path in js_files:
            issues = self.verify_file(file_path)
            all_issues.extend(issues)
            if issues:
                print(f"  âŒ {file_path}: å‘ç° {len(issues)} ä¸ªé—®é¢˜")
            else:
                print(f"  âœ… {file_path}: æ— é—®é¢˜")
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'total_files_checked': len(python_files) + len(html_files) + len(js_files),
            'total_issues': len(all_issues),
            'issues_by_type': {},
            'issues': all_issues
        }
        
        # æŒ‰é—®é¢˜ç±»å‹åˆ†ç±»
        for issue in all_issues:
            issue_type = issue['type']
            if issue_type not in report['issues_by_type']:
                report['issues_by_type'][issue_type] = 0
            report['issues_by_type'][issue_type] += 1
        
        return report
    
    def check_specific_patterns(self) -> Dict:
        """æ£€æŸ¥ç‰¹å®šçš„URLæ¨¡å¼"""
        results = {
            'redirects_with_prefix': [],
            'static_resources_with_prefix': [],
            'api_calls_with_prefix': [],
            'share_urls_with_prefix': []
        }
        
        # æ‰«ææ‰€æœ‰Pythonæ–‡ä»¶
        python_files = self.scan_files("./src", ['.py'])
        
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥é‡å®šå‘URL
                    if 'RedirectResponse(url=' in line and self.base_path in line:
                        results['redirects_with_prefix'].append({
                            'file': file_path,
                            'line': i,
                            'content': line.strip()
                        })
                    
                    # æ£€æŸ¥åˆ†äº«URL
                    if 'share_url' in line and self.base_path in line:
                        results['share_urls_with_prefix'].append({
                            'file': file_path,
                            'line': i,
                            'content': line.strip()
                        })
                    
                    # æ£€æŸ¥APIè°ƒç”¨
                    if 'fetch(' in line and f'{self.base_path}/api' in line:
                        results['api_calls_with_prefix'].append({
                            'file': file_path,
                            'line': i,
                            'content': line.strip()
                        })
            
            except Exception as e:
                continue
        
        # æ‰«æHTMLæ–‡ä»¶
        html_files = self.scan_files("./src", ['.html'])
        
        for file_path in html_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    # æ£€æŸ¥é™æ€èµ„æº
                    if ('src=' in line or 'href=' in line) and f'{self.base_path}/static' in line:
                        results['static_resources_with_prefix'].append({
                            'file': file_path,
                            'line': i,
                            'content': line.strip()
                        })
            
            except Exception as e:
                continue
        
        return results

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("LandPPT URLå‰ç¼€éªŒè¯å·¥å…·")
    print("=" * 60)
    
    verifier = URLPrefixVerifier()
    
    # è¿è¡ŒéªŒè¯
    report = verifier.run_verification()
    
    print(f"\néªŒè¯ç»“æœ:")
    print(f"  æ£€æŸ¥æ–‡ä»¶æ€»æ•°: {report['total_files_checked']}")
    print(f"  å‘ç°é—®é¢˜æ€»æ•°: {report['total_issues']}")
    
    if report['total_issues'] > 0:
        print(f"\né—®é¢˜ç±»å‹åˆ†å¸ƒ:")
        for issue_type, count in report['issues_by_type'].items():
            print(f"  {issue_type}: {count} ä¸ª")
        
        print(f"\nè¯¦ç»†é—®é¢˜åˆ—è¡¨:")
        for issue in report['issues']:
            print(f"  ğŸ“ {issue['file']}:{issue['line']}")
            print(f"     é—®é¢˜: {issue['issue']}")
            print(f"     å†…å®¹: {issue['content'][:100]}...")
            print()
        
        return False  # è¡¨ç¤ºå‘ç°é—®é¢˜
    else:
        print("âœ… æœªå‘ç°URLå‰ç¼€é—®é¢˜ï¼")
        
        # æ£€æŸ¥ç‰¹å®šçš„æ­£ç¡®æ¨¡å¼
        print(f"\næ£€æŸ¥æ­£ç¡®çš„URLæ¨¡å¼...")
        patterns = verifier.check_specific_patterns()
        
        print(f"  é‡å®šå‘URLä½¿ç”¨å‰ç¼€: {len(patterns['redirects_with_prefix'])} ä¸ª")
        print(f"  é™æ€èµ„æºä½¿ç”¨å‰ç¼€: {len(patterns['static_resources_with_prefix'])} ä¸ª")
        print(f"  APIè°ƒç”¨ä½¿ç”¨å‰ç¼€: {len(patterns['api_calls_with_prefix'])} ä¸ª")
        print(f"  åˆ†äº«URLä½¿ç”¨å‰ç¼€: {len(patterns['share_urls_with_prefix'])} ä¸ª")
        
        if any(patterns.values()):
            print(f"\nç¤ºä¾‹ï¼ˆæ­£ç¡®çš„URLæ¨¡å¼ï¼‰:")
            if patterns['redirects_with_prefix']:
                print(f"  é‡å®šå‘: {patterns['redirects_with_prefix'][0]['file']}:{patterns['redirects_with_prefix'][0]['line']}")
            if patterns['static_resources_with_prefix']:
                print(f"  é™æ€èµ„æº: {patterns['static_resources_with_prefix'][0]['file']}:{patterns['static_resources_with_prefix'][0]['line']}")
        
        return True  # è¡¨ç¤ºéªŒè¯é€šè¿‡

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)